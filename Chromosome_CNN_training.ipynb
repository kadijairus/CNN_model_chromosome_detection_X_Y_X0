{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPxQG00wUn8M"
   },
   "source": [
    "\n",
    "### OBJECTIVE\n",
    "\n",
    "Detect patients sex chromosomes from single cell metaphase chromosomes.\n",
    "\n",
    "### BACKGROUND\n",
    "\n",
    "### DATA\n",
    "\n",
    "**Source:** https://www.cellimagelibrary.org/pages/auto_chromosome_detector\n",
    "\n",
    "Total metaphase images: <number>\n",
    "\n",
    "Train: \n",
    "- male:\n",
    "- female:\n",
    "- monosomy X:\n",
    "\n",
    "Validation: \n",
    "- normal male:\n",
    "- normal female:\n",
    "- monosomy X:\n",
    "\n",
    "Test: \n",
    "- normal male:\n",
    "- normal female:\n",
    "- monosomy X:\n",
    "\n",
    "The input data are pictures of human single cell G-banded metaphase chromosomes in JPG format. All images are named using the scheme image_id_sexchromosomes.jpg. Variable \"image_id\" is a 6-digit unique identifier according to original dataset. Variable \"sexchromosomes\" is sex chromosomes labeled by the author (Kadi Jairus) according to International System for Human Cytogenetic Nomenclature (XX, XY or X).\n",
    "\n",
    "### METHOD\n",
    "\n",
    "- TensorFlow is used to develop and train a Convolutional Neural Network (CNN) architecture aimed at classifying images.\n",
    "- Different CNN architectures were tested to identify the most effective structure for our classification task.\n",
    "- Data augmentation techniques were applied including random rotations, flips, and brightness adjustments are applied to increase the robustness of the model and improve generalization.\n",
    "- A systematic search was conducted for the optimal set of hyperparameters, including learning rate, batch size, and number of epochs.\n",
    "- Various optimizers were tested such as Adam, SGD, and RMSprop to find the best algorithm for minimizing the loss function.\n",
    "- A validation strategy was implemented to monitor the model's performance on unseen data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoUeq4TYpYUD",
    "outputId": "150d7b94-8c03-4979-abad-987cb7b56cd7"
   },
   "outputs": [],
   "source": [
    "\"\"\"Imports modules and creates directory for files.\"\"\"\n",
    "\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "tallinn_tz = pytz.timezone('Europe/Tallinn')\n",
    "TODAY = datetime.now(tallinn_tz).strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "def create_report_dir(selected_model, batch_size, epochs):\n",
    "    # Makes directory for current training\n",
    "    report_dir = f'{TODAY}_{selected_model}_model_training_{batch_size}_batch_{epochs}_epochs'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(report_dir, exist_ok=True)\n",
    "        print(f\"Directory '{report_dir}' created successfully.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Could not create directory '{report_dir}'.\")\n",
    "\n",
    "    return report_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xpIhIDS68X6",
    "outputId": "b2f61127-6210-4ddb-88ef-fae0a14e0d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=2\n",
      "env: TF_NUM_INTEROP_THREADS=8\n",
      "env: SM_FRAMEWORK=tf.keras\n",
      "Setup succesful!\n",
      "Tensorflow version 2.16.1. \n",
      "Keras version: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sets up the environment and imports necessary libraries for TensorFlow and Keras.\"\"\"\n",
    "\n",
    "\n",
    "# Suppress tensorflow info messages\n",
    "%env TF_CPP_MIN_LOG_LEVEL=2\n",
    "%env TF_NUM_INTEROP_THREADS=8\n",
    "\n",
    "# Set segmentation_models framework to the correct keras\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, MaxPooling2D, AveragePooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Use mixed_float16, which is a good speedup on HPC cluster GPUs\n",
    "tf.keras.config.set_dtype_policy(\"mixed_float16\")\n",
    "\n",
    "try: \n",
    "    tf_version = tf.__version__\n",
    "    keras_version = tf.keras.__version__\n",
    "    print(f\"Setup succesful!\\nTensorflow version {tf_version}. \\nKeras version: {keras_version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Setup failed :( {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I'm sticking to tensorflow==2.16.1 because newer versions are basically broken on our system\n",
    "\n",
    "Temp Fix from: https://github.com/tensorflow/tensorflow/issues/62075#issuecomment-2387257399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gpu(s) found\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Optional code block. Checks the number of GPUs.\"\"\"\n",
    "\n",
    "\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "if num_gpus == 0:\n",
    "    raise SystemError('No GPU devices found')\n",
    "else:\n",
    "    print(f\"{num_gpus} gpu(s) found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UF8X7ER4hFD_"
   },
   "outputs": [],
   "source": [
    "\"\"\"Specifies the location of data. Creates directories for models and logs.\"\"\"\n",
    "\n",
    "\n",
    "# Uncomment below to download data into localstorage\n",
    "#!bash download_data.sh \"/localstorage/$USER/isic_data\"\n",
    "def create_dirs_for_model_and_logs(data_dir, report_dir):\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "    if not data_dir.exists():\n",
    "        raise ValueError(\"The specified data directory does not exist.\")\n",
    "        \n",
    "    train_dir = data_dir / \"train\"\n",
    "    val_dir = data_dir / \"val\"\n",
    "    test_dir = data_dir / \"test\"\n",
    "    \n",
    "    logs_path = f\"{report_dir}/logs\"\n",
    "    models_path = \"models\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(logs_path, exist_ok=True)\n",
    "        os.makedirs(models_path, exist_ok=True) \n",
    "        print(f\"Directories for logs and models created successfully in {report_dir}.\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission denied: Could not create needed directories. {e}\")\n",
    "\n",
    "    return (train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defines how picture data will be generated.\"\"\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_data_generators():\n",
    "    # Define a training image data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,  # Rescale pixel values: 0 to 1, not to 255.\n",
    "        rotation_range=20,  # Random rotations, 20 degrees.\n",
    "        width_shift_range=None,  # Random horizontal shifts\n",
    "        height_shift_range=None,  # Random vertical shifts\n",
    "        shear_range=0.2,  # Shearing (darkness)\n",
    "        zoom_range=0.05,  # Zooming\n",
    "        horizontal_flip=True,  # Horizontal flipping\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Defines a testing/validation image data generator with NO augmentation, only rescaling\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return(train_datagen, val_datagen, test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optional code block. Remove checkpoints if 4 classes instead of 3.\"\"\"\n",
    "\n",
    "\n",
    "def remove_ipynb_checkpoints(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if '.ipynb_checkpoints' in dirs:\n",
    "            checkpoint_path = os.path.join(root, '.ipynb_checkpoints')\n",
    "            shutil.rmtree(checkpoint_path)\n",
    "            print(f\"Removed {checkpoint_path}\")\n",
    "\n",
    "    # Apply to train, val, and test directories\n",
    "    remove_ipynb_checkpoints(train_dir)\n",
    "    remove_ipynb_checkpoints(val_dir)\n",
    "    remove_ipynb_checkpoints(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generates training, validation and testing data.\"\"\"\n",
    "\n",
    "\n",
    "def get_data_generators(img_size, batch_size):\n",
    "    # Changes parameters after each batch\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Loads images from the testing directory\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',  # Matching the class_mode of the training data\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False  # Ensure the generator does not shuffle the images\n",
    "    )\n",
    "    \n",
    "    print(\"Class indices for training data:\", train_generator.class_indices)\n",
    "    print(\"Class indices for validation data:\", val_generator.class_indices)\n",
    "    print(\"Class indices for testing data:\", test_generator.class_indices)\n",
    "\n",
    "    return (train_generator, val_generator, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Option 1. Defines the pre-trained Xception model.\"\"\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "def create_xception(input_shape, num_classes, dropout_rate, l2_factor=0.01):\n",
    "    \"\"\"\n",
    "    Define model architecture.\n",
    "    \n",
    "    :param int: height, width, channels\n",
    "    :param int: number of classes\n",
    "    :return: model\n",
    "    \"\"\"    \n",
    "    # Load Xception base without top layers\n",
    "    base_model = Xception(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(input_shape)\n",
    "    )\n",
    "    \n",
    "    # Only train last layers\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-10]:  # Freeze all layers except the last 10\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_factor)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(l2_factor)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_factor))\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Option 2. Defines pretrained Alexnet model with dropout.\"\"\"\n",
    "\n",
    "\n",
    "def create_alexnet(input_shape, num_classes):\n",
    "    modelAlexNet = Sequential([\n",
    "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'),\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return modelAlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Specifies variables, compiles model with single hyperparameter set and creates summary.\"\"\"\n",
    "\n",
    "\n",
    "# Define class weights in float32 for numerical stability\n",
    "class_weights = tf.constant([1.0, 1.0, 1.51], dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    # Ensure y_true and y_pred are cast to float32 for stability\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Apply weights to the one-hot encoded labels\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=1)\n",
    "    \n",
    "    # Compute the unweighted categorical crossentropy loss\n",
    "    unweighted_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Apply weights to the loss\n",
    "    weighted_loss = unweighted_loss * weights\n",
    "    return weighted_loss\n",
    "    \n",
    "def compile_model(report_dir, selected_model, input_shape, num_classes, dropout_rate, optimizer_name, learning_rate):\n",
    "    \n",
    "    if selected_model == \"xception\":\n",
    "        model = create_xception(input_shape, num_classes, dropout_rate)\n",
    "    elif selected_model == \"alexnet\":\n",
    "        model = create_alexnet(input_shape, num_classes)\n",
    "    else:\n",
    "        model = create_cnn(num_classes)\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected optimizer name: {optimizer_name}\")\n",
    "       \n",
    "    # Compiles the model 'adam' or 'sgd' optimizer. \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=weighted_categorical_crossentropy,\n",
    "                  #metrics=['accuracy', Precision(), Recall()])    \n",
    "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
    "   \n",
    "    # Saves model summary in table format\n",
    "    summary_file = f\"{report_dir}/{TODAY}_Model_{selected_model}_architecture_summary_optimizer_{optimizer}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    # Shows the model\n",
    "    model.summary()\n",
    "    \n",
    "    # Shows model as a graph\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=f\"{report_dir}/{TODAY}_Model_{selected_model}_graph_optimizer_{optimizer_name}.png\",\n",
    "        show_shapes=True,\n",
    "        show_dtype=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=True,\n",
    "        dpi=60,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains model with single hyperparameter set and writes to file.\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def train_model(report_dir, model, train_generator, val_generator, epochs, batch_size, optimizer):\n",
    "    # Ensure report directory exists\n",
    "    import os\n",
    "    if not os.path.exists(report_dir):\n",
    "        os.makedirs(report_dir)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=f\"{report_dir}/best_model.keras\", save_best_only=True, monitor='val_loss')\n",
    "    ]\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "        class_weight={0: 1.0, 1: 1.0, 2: 1.51},  # Adjust weights as needed\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Print history keys\n",
    "    keys = history.history.keys()\n",
    "    print(f\"Model history keys are: \\n{keys}\")\n",
    "\n",
    "    # Plot metrics\n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall']\n",
    "    titles = ['Loss', 'Accuracy', 'Precision', 'Recall']\n",
    "    f, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        row, col = divmod(i, 2)\n",
    "        if metric in history.history:\n",
    "            ax[row, col].plot(history.history[metric], label=f\"Train {metric}\", color='b')\n",
    "            ax[row, col].plot(history.history.get(f\"val_{metric}\", []), label=f\"Validation {metric}\", color='r')\n",
    "            ax[row, col].set_title(titles[i])\n",
    "            ax[row, col].legend(loc=\"best\")\n",
    "        else:\n",
    "            print(f\"Metric {metric} not found in history.history. Skipping plot.\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    filename = f\"{report_dir}/{epochs}_epochs_{batch_size}_batches_training_plot.png\"\n",
    "    try:\n",
    "        plt.savefig(filename)\n",
    "        print(f\"Training plot saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Saving plot failed: {e}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def train_model(report_dir, model, train_generator, val_generator, epochs, batch_size, optimizer):\n",
    "    # Fit the model to the training data\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Ensures the model sees the x_train samples per epoch\n",
    "                                                                                # allows you to control how much data the model\n",
    "                                                                                # should consume before declaring one epoch complete and moving on to the next epoch.\n",
    "        epochs=epochs,  # Number of epochs to train for\n",
    "        #class_weight={0: 1.0, 1: 1.0, 2: 1.51},\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // val_generator.batch_size\n",
    "    )\n",
    "\n",
    "    keys = model.history.history.keys()\n",
    "    print(f\"Model history keys are: \\n{keys}\")\n",
    "    \n",
    "    # EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    callbacks = [early_stopping]\n",
    "    # Generate plots\n",
    "    f,ax=plt.subplots(2,2, figsize=(12,6))\n",
    "    try:\n",
    "      #1st subplot: training loss and validation loss\n",
    "      ax[0, 0].plot(model.history.history['loss'],color='b',label='train_loss')\n",
    "      ax[0, 0].plot(model.history.history['val_loss'],color='r',label='val_loss')\n",
    "      ax[0, 0].legend(loc=\"upper right\")\n",
    "    except Exception as e:\n",
    "        print(f'Creating plot 0,0 failed: {e}')\n",
    "    \n",
    "    try:\n",
    "      #2nd subplot: training accuracy and validation accuracy\n",
    "      ax[0, 1].plot(model.history.history['accuracy'],color='b',label='train_accuracy')\n",
    "      ax[0, 1].plot(model.history.history['val_accuracy'],color='r',label='val_accuracy')\n",
    "      ax[0, 1].legend(loc=\"lower right\")\n",
    "    except Exception as e:\n",
    "        print(f'Creating plot 0,1 failed: {e}')\n",
    "    \n",
    "    try:\n",
    "      #3rd subplot: training precision and validation precision\n",
    "      ax[1, 0].plot(model.history.history['precision'],color='b',label='train_precision')\n",
    "      ax[1, 0].plot(model.history.history['val_precision'],color='r',label='val_precision')\n",
    "      ax[1, 0].legend(loc=\"lower right\")\n",
    "    except Exception as e:\n",
    "        print(f'Creating plot 1,0 failed: {e}')\n",
    "    \n",
    "    try:\n",
    "      #4th subplot: training recall and validation recall\n",
    "      ax[1, 1].plot(model.history.history['recall'],color='b',label='train_recall')\n",
    "      ax[1, 1].plot(model.history.history['val_recall'],color='r',label='val_recall')\n",
    "      ax[1, 1].legend(loc=\"lower right\")\n",
    "    except Exception as e:\n",
    "        print(f'Creating plot 1,1 failed: {e}')\n",
    "    \n",
    "    # Save plots\n",
    "    filename = f\"{report_dir}/{TODAY}_CNN_training_plot_{epochs}_epochs_{batch_size}_batches_optimizer_{optimizer}.png\"\n",
    "    try:\n",
    "        plt.savefig(filename)\n",
    "        print('Saved figure')\n",
    "    except Exception as e:\n",
    "        print(f'Saving figure to first location failed: {e}')\n",
    "        try:\n",
    "          plt.savefig('training_image_bug')\n",
    "          print('Saved figure to home directory')\n",
    "        except Exception as e:\n",
    "          print(f'Saving figure failed: {e}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Option 2. Trains model with multiple sets of hyperparameters and writes to file.\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Define a helper to create a log directory\n",
    "def get_run_logdir(run_name, root_logdir):\n",
    "    run_id = time.strftime(run_name + \"_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "def compile_train_and_test_with_multiple_hp(\n",
    "    REPORT_DIR,\n",
    "    train_generator,\n",
    "    val_generator,\n",
    "    SELECTED_MODEL,\n",
    "    INPUT_SHAPE,\n",
    "    NUM_CLASSES,\n",
    "    HP_LEARNING_RATE,\n",
    "    HP_DROPOUT,\n",
    "    HP_OPTIMIZER,\n",
    "    METRIC_ACCURACY,\n",
    "    EPOCHS,\n",
    "    BATCH_SIZE,\n",
    "):\n",
    "    root_logdir = os.path.join(os.curdir, \"logs_hp_training\")\n",
    "    run_name = \"run\"\n",
    "    \n",
    "    # Define HParams\n",
    "    hparams = [HP_LEARNING_RATE, HP_DROPOUT, HP_OPTIMIZER]\n",
    "    metric = [hp.Metric(METRIC_ACCURACY, display_name=\"Accuracy\")]\n",
    "\n",
    "    # Set up TensorBoard for HParam logging\n",
    "    with tf.summary.create_file_writer(os.path.join(root_logdir, f\"{TODAY}_hparam_tuning\")).as_default():\n",
    "        hp.hparams_config(hparams=hparams, metrics=metric)\n",
    "\n",
    "    session_num = 0\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "                hparams = {\n",
    "                    HP_LEARNING_RATE: learning_rate,\n",
    "                    HP_DROPOUT: dropout_rate,\n",
    "                    HP_OPTIMIZER: optimizer,\n",
    "                }\n",
    "                run_dir = get_run_logdir(run_name, root_logdir)\n",
    "                print(f\"--- Starting trial: {run_dir}\")\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                session_num += 1\n",
    "\n",
    "                # Initialize model\n",
    "                model = compile_model(REPORT_DIR, SELECTED_MODEL, INPUT_SHAPE, NUM_CLASSES, \n",
    "                                      dropout_rate, optimizer, learning_rate)\n",
    "                \n",
    "                # Write training info\n",
    "                info_file = os.path.join(REPORT_DIR, f\"{TODAY}_training_info.txt\")\n",
    "                with open(info_file, \"w\") as f:\n",
    "                    f.write(f\"Training model: {SELECTED_MODEL}\\n\")\n",
    "                    f.write(f\"Input shape: {INPUT_SHAPE}\\n\")\n",
    "                    f.write(f\"Epochs: {EPOCHS}\\n\")\n",
    "                    f.write(f\"Batch size: {BATCH_SIZE}\\n\")\n",
    "                    f.write(f\"Optimizer: {optimizer}\\n\")\n",
    "                    f.write(f\"Learning rate: {learning_rate}\\n\")\n",
    "                    f.write(f\"Dropout rate: {dropout_rate}\\n\")\n",
    "\n",
    "                # Train model\n",
    "                trained_model = train_model(REPORT_DIR, model, train_generator, val_generator, EPOCHS, BATCH_SIZE, optimizer)\n",
    "                \n",
    "                # Save model\n",
    "                save_path = os.path.join(\"models\", f\"{TODAY}_Cyto_cnn_{SELECTED_MODEL}.keras\")\n",
    "                trained_model.save(save_path)\n",
    "                \n",
    "                # Test model\n",
    "                test_model(save_path, REPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test model.\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "\n",
    "def test_model(model_path, report_dir):\n",
    "    try: \n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        print(f\"Loading model successful! Path: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Loading model failed. {e}\")\n",
    "\n",
    "    # Predictions and true labels\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_labels = test_generator.classes\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    # Keras metrics\n",
    "    accuracy_metric = Accuracy()\n",
    "    accuracy_metric.update_state(true_labels, predicted_classes)\n",
    "    accuracy = accuracy_metric.result().numpy()\n",
    "    \n",
    "    # Generate a confusion matrix manually\n",
    "    conf_matrix = np.zeros((len(class_labels), len(class_labels)), dtype=int)\n",
    "    for true, pred in zip(true_labels, predicted_classes):\n",
    "        conf_matrix[true, pred] += 1\n",
    "    \n",
    "    # Calculate precision and recall for each class\n",
    "    precision_metric = Precision()\n",
    "    recall_metric = Recall()\n",
    "    \n",
    "    precision_metric.update_state(to_categorical(true_labels, num_classes=len(class_labels)), predictions)\n",
    "    recall_metric.update_state(to_categorical(true_labels, num_classes=len(class_labels)), predictions)\n",
    "    \n",
    "    precision = precision_metric.result().numpy()\n",
    "    recall = recall_metric.result().numpy()\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Save the report\n",
    "    filename = f\"{report_dir}/{TODAY}_classification_report_model_testing.txt\"\n",
    "    try:\n",
    "        os.makedirs(report_dir, exist_ok=True)\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"Classification Report\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "            f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "            f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "            f.write(\"\\nConfusion Matrix:\\n\")\n",
    "            for row in conf_matrix:\n",
    "                f.write(' '.join(map(str, row)) + '\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report: {e}\")\n",
    "    \n",
    "    # Plot incorrect predictions\n",
    "    incorrect_indices = np.where(predicted_classes != true_labels)[0]\n",
    "    \n",
    "    # Reset generator\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Visualize incorrect predictions\n",
    "    num_samples_to_plot = 10\n",
    "    plotted_count = 0\n",
    "    \n",
    "    for i in range(len(test_generator)):\n",
    "        images, labels = next(test_generator)\n",
    "    \n",
    "        # Check batch size\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "    \n",
    "        batch_start_index = i * test_generator.batch_size\n",
    "        batch_end_index = batch_start_index + len(labels)\n",
    "    \n",
    "        batch_incorrect_indices = [idx for idx in incorrect_indices\n",
    "                                   if batch_start_index <= idx < batch_end_index]\n",
    "        batch_relative_indices = [idx - batch_start_index for idx in batch_incorrect_indices]\n",
    "    \n",
    "        for idx in batch_relative_indices:\n",
    "            if plotted_count >= num_samples_to_plot:\n",
    "                break\n",
    "    \n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow((images[idx] * 255).astype(\"uint8\"))\n",
    "            true_class = class_labels[true_labels[batch_start_index + idx]]\n",
    "            predicted_class = class_labels[predicted_classes[batch_start_index + idx]]\n",
    "    \n",
    "            plt.title(f\"True: {true_class}, Predicted: {predicted_class}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "            plot_filename = f\"{report_dir}/Wrong_prediction_{plotted_count + 1}_{true_class}_predicted_{predicted_class}.png\"\n",
    "            plt.savefig(plot_filename, format='png')\n",
    "            plt.show()\n",
    "    \n",
    "            plotted_count += 1\n",
    "    \n",
    "        if plotted_count >= num_samples_to_plot:\n",
    "            break\n",
    "\n",
    "        print(\"Testing model succesful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '2024-12-31_11-39_xception_model_training_2_batch_70_epochs' created successfully.\n",
      "Directories for logs and models created successfully in 2024-12-31_11-39_xception_model_training_2_batch_70_epochs.\n",
      "Found 1023 images belonging to 3 classes.\n",
      "Found 288 images belonging to 3 classes.\n",
      "Found 288 images belonging to 3 classes.\n",
      "Class indices for training data: {'female': 0, 'male': 1, 'monosomy': 2}\n",
      "Class indices for validation data: {'female': 0, 'male': 1, 'monosomy': 2}\n",
      "Class indices for testing data: {'female': 0, 'male': 1, 'monosomy': 2}\n",
      "Class indices: {'female': 0, 'male': 1, 'monosomy': 2}\n",
      "x_batch shape: (2, 300, 300, 3), y_batch shape: (2, 3)\n",
      "y_batch: [[0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "tf.Tensor([0.35667497 0.22314353], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main. Common for options 1 and 2.\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Adjusts the parameters.\"\"\"\n",
    "IMG_SIZE = (300, 300)\n",
    "INPUT_SHAPE = (300, 300, 3)\n",
    "SELECTED_MODEL = \"xception\"\n",
    "# Uses 'adam' or 'sgd' optimizer\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 70\n",
    "DROPOUT_RATE = 0.3\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "\"\"\"Creates directories.\"\"\"\n",
    "REPORT_DIR = create_report_dir(SELECTED_MODEL, BATCH_SIZE, EPOCHS)\n",
    "\n",
    "dirs = create_dirs_for_model_and_logs(\"data\", REPORT_DIR)\n",
    "train_dir = dirs[0]\n",
    "val_dir = dirs[1]\n",
    "test_dir = dirs[2]\n",
    "\n",
    "\"\"\"Generates data.\"\"\"\n",
    "data_gens = create_data_generators()\n",
    "train_datagen = data_gens[0]\n",
    "val_datagen = data_gens[1]\n",
    "test_datagen = data_gens[2]\n",
    "\n",
    "generators = get_data_generators(IMG_SIZE, BATCH_SIZE)\n",
    "train_generator = generators[0]\n",
    "val_generator = generators[1]\n",
    "test_generator = generators[2]\n",
    "\n",
    "\"\"\"Validates generator\"\"\"\n",
    "print(\"Class indices:\", train_generator.class_indices)\n",
    "for x_batch, y_batch in train_generator:\n",
    "    print(f\"x_batch shape: {x_batch.shape}, y_batch shape: {y_batch.shape}\")\n",
    "    print(f\"y_batch: {y_batch}\")\n",
    "    break\n",
    "\n",
    "\"\"\"Validates custom loss function\"\"\"\n",
    "y_true = tf.constant([[0, 1, 0], [1, 0, 0]], dtype=tf.float32)  # Example one-hot labels\n",
    "y_pred = tf.constant([[0.1, 0.7, 0.2], [0.8, 0.1, 0.1]], dtype=tf.float32)  # Example predictions\n",
    "print(weighted_categorical_crossentropy(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,132,203</span> (80.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,132,203\u001b[0m (80.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,767,043</span> (22.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,767,043\u001b[0m (22.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,365,160</span> (58.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,365,160\u001b[0m (58.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Testing with small batch\n",
      "Loss for the batch: [1.5405672 1.4955688]\n",
      "Training model xception:\n",
      " epochs: 70 \n",
      " batch_size: 2 \n",
      " optimizer: adam \n",
      " learning rate: 0.0001 \n",
      " dropout_rate: 0.3\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge/envs/ogun/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735637975.860544 2378272 service.cc:145] XLA service 0x7f9ff4002ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735637975.860592 2378272 service.cc:153]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-12-31 11:39:41.511928: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %reduce-window.1695 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.509, f16[] %constant.1690), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1691, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-12-31 11:39:48.190008: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 7.678268903s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %reduce-window.1695 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.509, f16[] %constant.1690), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1691, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-12-31 11:39:51.723930: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %reduce-window.2275 = f16[2,37,37,256]{3,2,1,0} reduce-window(f16[2,74,74,256]{3,2,1,0} %constant.561, f16[] %constant.2270), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x0_1x0_1x0_0}, to_apply=%max_F16.2271, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block3_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-12-31 11:39:53.593951: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.870389094s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %reduce-window.2275 = f16[2,37,37,256]{3,2,1,0} reduce-window(f16[2,74,74,256]{3,2,1,0} %constant.561, f16[] %constant.2270), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x0_1x0_1x0_0}, to_apply=%max_F16.2271, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block3_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/511\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:13:05\u001b[0m 44s/step - accuracy: 0.0000e+00 - loss: 4.6791 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735638014.710753 2378272 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-12-31 11:40:23.141916: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  %reduce-window.1689 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.511, f16[] %constant.1684), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1685, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-12-31 11:40:26.949468: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 7.808154592s\n",
      "Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  %reduce-window.1689 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.511, f16[] %constant.1684), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1685, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/511\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12:03\u001b[0m 37s/step - accuracy: 0.1250 - loss: 4.6600 - precision: 0.0000e+00 - recall: 0.0000e+00    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 11:41:03.897910: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 8s:\n",
      "\n",
      "  %reduce-window.1689 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.511, f16[] %constant.1684), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1685, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-12-31 11:41:04.366389: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 8.469313556s\n",
      "Constant folding an instruction is taking > 8s:\n",
      "\n",
      "  %reduce-window.1689 = f16[2,74,74,128]{3,2,1,0} reduce-window(f16[2,147,147,128]{3,2,1,0} %constant.511, f16[] %constant.1684), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x1_1x1_1x0_0}, to_apply=%max_F16.1685, metadata={op_type=\"MaxPool\" op_name=\"sequential_1/xception_1/block2_pool_1/MaxPool2d\" source_file=\"/opt/miniforge/envs/ogun/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/511\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:09:44\u001b[0m 37s/step - accuracy: 0.2917 - loss: 4.6305 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "\"\"\"Option 1. Main with single model.\"\"\"\n",
    "\n",
    "\"\"\"Compiles model.\"\"\" \n",
    "model = compile_model(REPORT_DIR, SELECTED_MODEL, INPUT_SHAPE, NUM_CLASSES, DROPOUT_RATE, OPTIMIZER, LEARNING_RATE)\n",
    "\n",
    "\"\"\"Validating custom loss function\"\"\" \n",
    "print(\"Testing with small batch\") \n",
    "x_batch, y_batch = next(iter(train_generator)) \n",
    "y_pred = model(x_batch) \n",
    "loss = weighted_categorical_crossentropy(y_batch, y_pred) \n",
    "print(\"Loss for the batch:\", loss.numpy())\n",
    "\n",
    "\"\"\"Writes training details to file.\"\"\" \n",
    "print(f\"Training model {SELECTED_MODEL}:\\n epochs: {EPOCHS} \\n batch_size: {BATCH_SIZE} \\n optimizer: {OPTIMIZER} \\n learning rate: {LEARNING_RATE} \\n dropout_rate: {DROPOUT_RATE}\") \n",
    "info_file = os.path.join(REPORT_DIR, f\"{TODAY}training_info{EPOCHS}{BATCH_SIZE}{OPTIMIZER}.txt\") \n",
    "with open(info_file, \"w\") as f: \n",
    "    f.write(f\"Training model {SELECTED_MODEL}:\\n\") \n",
    "    f.write(f\"Input shape {str(INPUT_SHAPE)}:\\n\") \n",
    "    f.write(f\"epochs: {EPOCHS}\\n\") \n",
    "    f.write(f\"batch_size: {BATCH_SIZE}\\n\") \n",
    "    f.write(f\"optimizer: {OPTIMIZER}\\n\") \n",
    "    f.write(f\"learning rate: {LEARNING_RATE}\\n\") \n",
    "    f.write(f\"dropout_rate: {DROPOUT_RATE}\\n\")\n",
    "\n",
    "\"\"\"Trains model.\"\"\" \n",
    "trained_model = train_model(REPORT_DIR, model, train_generator, val_generator, EPOCHS, BATCH_SIZE, OPTIMIZER)\n",
    "\n",
    "\"\"\"Saves model.\"\"\" \n",
    "save_path = f\"models/{TODAY}Cyto_cnn{SELECTED_MODEL}model{EPOCHS}epochs{BATCH_SIZE}batches_optimizer{OPTIMIZER}lr{LEARNING_RATE}.keras\" \n",
    "trained_model.save(save_path)\n",
    "\n",
    "\"\"\"Tests model.\"\"\" \n",
    "test_model(save_path, REPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: ./logs_hp_training/run_2024_12_31-10_37_37\n",
      "{'learning_rate': 1e-05, 'dropout': 0.0, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,132,203</span> (80.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,132,203\u001b[0m (80.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,767,043</span> (22.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,767,043\u001b[0m (22.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,365,160</span> (58.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,365,160\u001b[0m (58.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge/envs/ogun/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret loss identifier: weighted_categorical_crossentropy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m HP_OPTIMIZER \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mHParam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m, hp\u001b[38;5;241m.\u001b[39mDiscrete([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      9\u001b[0m METRIC_ACCURACY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcompile_train_and_test_with_multiple_hp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREPORT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mSELECTED_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_SHAPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHP_LEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHP_DROPOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mHP_OPTIMIZER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRIC_ACCURACY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 71\u001b[0m, in \u001b[0;36mcompile_train_and_test_with_multiple_hp\u001b[0;34m(REPORT_DIR, train_generator, val_generator, SELECTED_MODEL, INPUT_SHAPE, NUM_CLASSES, HP_LEARNING_RATE, HP_DROPOUT, HP_OPTIMIZER, METRIC_ACCURACY, EPOCHS, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     68\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropout rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREPORT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     74\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTODAY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Cyto_cnn_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSELECTED_MODEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[117], line 63\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(report_dir, model, train_generator, val_generator, epochs, batch_size, optimizer)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(report_dir, model, train_generator, val_generator, epochs, batch_size, optimizer):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures the model sees the x_train samples per epoch\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[38;5;66;43;03m# allows you to control how much data the model\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[38;5;66;43;03m# should consume before declaring one epoch complete and moving on to the next epoch.\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train for\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#class_weight={0: 1.0, 1: 1.0, 2: 1.51},\u001b[39;49;00m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel history keys are: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mkeys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniforge/envs/ogun/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniforge/envs/ogun/lib/python3.11/site-packages/keras/src/losses/__init__.py:207\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret loss identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret loss identifier: weighted_categorical_crossentropy"
     ]
    }
   ],
   "source": [
    "\"\"\"Option 2. Main with hp.\"\"\"\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-05]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.4, 0.5, 0.]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "compile_train_and_test_with_multiple_hp(REPORT_DIR, train_generator, val_generator,  \n",
    "                                        SELECTED_MODEL, INPUT_SHAPE, \n",
    "                                        NUM_CLASSES, HP_LEARNING_RATE, HP_DROPOUT, \n",
    "                                        HP_OPTIMIZER, METRIC_ACCURACY,\n",
    "                                        EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
